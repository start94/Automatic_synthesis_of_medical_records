{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMuPAaD4BN9Swzr8F08iOjf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/start94/Automatic_synthesis_of_medical_records/blob/main/Sintesi_automatica__di_cartelle__cliniche.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch requests\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HQ897J8DBxgO",
        "outputId": "817e6cf8-3bf4-4084-e4a7-20e731deadcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRESENTAZIONE DEL PROGETTO\n",
        "Il progetto costruisce un sistema automatico in grado di:\n",
        "Leggere cartelle cliniche da un file JSON (via URL)\n",
        "Generare un riassunto automatico con un modello NLP pre-addestrato (BART), salvare i risultati in un file clinical_summaries.json\n",
        "stampare i riassunti e alcune statistiche finali\n",
        "\n",
        "Importazione delle librerie:\n",
        "transformers: usato per caricare il modello BART (da HuggingFace).\n",
        "torch: per gestire i tensori e l'esecuzione su GPU.\n",
        "warnings: per disattivare avvisi non critici.\n",
        "datetime: per aggiungere un timestamp alla generazione.\n",
        "\n",
        "Caricamento del modello\n",
        "model_name = \"facebook/bart-large-cnn\"\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "si carica BART, un modello di summarization.\n",
        "si controlla se √® disponibile la GPU con torch.cuda.is_available() e si trasferisce l√¨ il modello. Per rendere il processo pi√π veloce\n",
        "\n",
        "Funzione di preparazione del testo clinico\n",
        "def prepare_clinical_text(patient_data):\n",
        "Questa funzione prepara un testo coerente per ogni paziente, combinando:\n",
        "Nome del paziente\n",
        "ricoveri con date, diagnosi, anamnesi, prognosi\n",
        "Farmaci somministrati e risultati di esami\n",
        " Serve per dare al modello un contesto completo da cui generare un riassunto.\n",
        "\n",
        "Funzione di generazione del riassunto\n",
        "def generate_summary(text, max_length=150, min_length=50):\n",
        "Il testo viene tokenizzato (convertito in numeri).\n",
        "il modello BART genera un riassunto.\n",
        "il risultato viene decodificato in linguaggio naturale.\n",
        "Parametri:\n",
        "max_length, min_length: controllano la lunghezza del riassunto.\n",
        "num_beams=4: beam search per migliorare la qualit√†.\n",
        "\n",
        "Funzione per caricare i dati clinici\n",
        "def load_clinical_data(url: str):\n",
        "Scarica un file .json contenente le cartelle cliniche da un URL remoto.\n",
        "\n",
        "Gestisce gli errori di rete o formattazione JSON.\n",
        "Ritorna una lista di pazienti con le loro informazioni cliniche.\n",
        "Caricamento dei dati dal file JSON\n",
        "json_url = \"...\"\n",
        "clinical_data = load_clinical_data(json_url)\n",
        "carica i dati dalla URL specificata.\n",
        "Se il file non √® accessibile, mostra un errore e inizializza una lista vuota.\n",
        "\n",
        "Generazione dei riassunti\n",
        "ciclo for\n",
        "for patient in clinical_data:\n",
        "itera ogni paziente.\n",
        "\n",
        "\n",
        "Salvataggio dei risultati\n",
        "\n",
        "with open('clinical_summaries.json', 'w') as f:\n",
        "I risultati vengono salvati in un file JSON.\n",
        "Contiene tutti i riassunti e le informazioni di contesto:\n",
        "Data di generazione\n",
        "modello usato\n",
        "numero di pazienti\n",
        "\n",
        "Visualizzazione dei riassunti\n",
        "stampa ogni riassunto generato con:\n",
        "nome del paziente\n",
        "numero di ricoveri\n",
        "lunghezza del testo originale\n",
        "riassunto generato\n",
        "\n",
        "Statistiche finali\n",
        "print(f\"Total hospitalizations: ...\")\n",
        "Mostra:\n",
        "numero totale di pazienti processati\n",
        "numero totale di ricoveri\n",
        "lunghezza media del testo clinico\n",
        "modello utilizzato\n",
        "dispositivo (GPU/CPU)\n",
        "Conclusione\n",
        "Il sistema costruito √®:\n",
        "Riproducibile (usa dati esterni da URL)\n",
        "Scalabile (funziona per molti pazienti)\n",
        "Realistico (simula un'applicazione in ambito ospedaliero)\n",
        "Basato su NLP: sfrutta modelli pre-addestrati di HuggingFace per NLP in italiano o inglese.\n",
        "\n"
      ],
      "metadata": {
        "id": "2mqpZE6TIiQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "print(\"üè• Automatic clinical record synthesis system\")\n",
        "\n",
        "\n",
        "# 1. MODEL LOADING (HUGGINGFACE)\n",
        "print(\"Loading BART model\")\n",
        "model_name = \"facebook/bart-large-cnn\" # specifica il modello\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)  #carica il tokenizzatore associato al modello\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "# Controlla se √® disponibile una GPU e sposta il modello su di essa per essere pi√π veloce\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(f\"Model loaded on: {device}\")\n",
        "\n",
        "# 2. FUNCTION FOR TEXT PREPARATION\n",
        "def prepare_clinical_text(patient_data):\n",
        "    \"\"\"\n",
        "    Prepares the clinical text for each patient by concatenating all the relevant information\n",
        "    from their hospitalizations. This creates a comprehensive input for the summarization model.\n",
        "    \"\"\"\n",
        "    patient_name = patient_data['patient_name']\n",
        "    text_parts = [f\"Patient: {patient_name}\"]\n",
        "\n",
        "    # cilco for per scorrere ogni cartella di ricovero del paziente\n",
        "    for i, hospitalization in enumerate(patient_data['hospitalizations'], 1):\n",
        "        admission_date = hospitalization['admission_date']\n",
        "        discharge_date = hospitalization['discharge_date']\n",
        "        diagnosis = hospitalization['diagnosis']\n",
        "        anamnesis = hospitalization['anamnesis']\n",
        "        prognosis = hospitalization['prognosis']\n",
        "\n",
        "        # costruisco il testo per l'attuale ricovero ospedaliero\n",
        "        hospitalization_text = f\"Hospitalization {i}: From {admission_date} to {discharge_date}. \"\n",
        "        hospitalization_text += f\"Diagnosis: {diagnosis}. \"\n",
        "        hospitalization_text += f\"Anamnesis: {anamnesis}. \"\n",
        "        hospitalization_text += f\"Prognosis: {prognosis}. \"\n",
        "\n",
        "        # aggiungere farmaci se disponibili\n",
        "        if hospitalization['medications']:\n",
        "            medications = \", \".join(hospitalization['medications'])\n",
        "            hospitalization_text += f\"Medications administered: {medications}. \"\n",
        "\n",
        "\n",
        "# condizione che aggiunge i risultati del test se disponibili\n",
        "        if hospitalization['test_results']:\n",
        "            test_results = \". \".join(hospitalization['test_results'])\n",
        "            hospitalization_text += f\"Test results: {test_results}. \"\n",
        "\n",
        "        text_parts.append(hospitalization_text)\n",
        "\n",
        "    return \" \".join(text_parts)\n",
        "\n",
        "# 3. FUNCTION FOR SUMMARY GENERATION\n",
        "def generate_summary(text, max_length=150, min_length=50):\n",
        "    \"\"\"\n",
        "    Ecco cosa fa questa funzione :\n",
        "    Genera un riepilogo utilizzando il modello BART.\n",
        "    tokenizza il testo di input: convertilo in ID numerici comprensibili dal modello.\n",
        "    max_length=1024: limita la lunghezza della sequenza di input per evitare di superare la capacit√† del modello.\n",
        "    truncation=True: tronca il testo se √® pi√π lungo di max_length.\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "    inputs = inputs.to(device)\n",
        "\n",
        "    # genera il riepilogo utilizzando il modello in modalit√† di valutazione,nessun calcolo del gradiente\n",
        "    with torch.no_grad():\n",
        "        summary_ids = model.generate(\n",
        "            inputs,\n",
        "            max_length=max_length,    # lunghezza massima del riepilogo generato\n",
        "            min_length=min_length,    # lunghezza min.\n",
        "            length_penalty=2.0,       # penalit√† per i riassunti brevi, incoraggia quelli pi√π lunghi\n",
        "            num_beams=4,              # migliora la qualit√† del riepilogo\n",
        "            early_stopping=True       # qui invece interropmppo  la generazione quando viene prodotto un token finale corretto\n",
        "        )\n",
        "\n",
        "    \"\"\"\n",
        "    skip_special_tokens=True\n",
        "    Indica di saltare i token speciali come <pad>, <s>, </s>, [CLS], [SEP] che servono al modello ma non devono apparire nel testo finale.\n",
        "    Senza questo parametro, il riassunto potrebbe contenere simboli inutili o confusi per chi leggee.\n",
        "    \"\"\"\n",
        "\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "#  FUNCTION TO LOAD CLINICAL DATA\n",
        "import requests\n",
        "def load_clinical_data(url: str) -> list or None:\n",
        "    \"\"\"\n",
        "Carica i dati clinici da un URL specificato.\n",
        "Argomenti: url (str): URL del file JSON contenente le cartelle cliniche.\n",
        "Restituisce: elenco o Nessuno: il contenuto del file JSON come elenco di dizionari,\n",
        "oppure nessuno se si verifica un errore durante il download o l'analisi.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\" Loading data from URL: {url}\")\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = json.loads(response.text)\n",
        "        return data\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\" Network/HTTP error during URL loading: {e}\")\n",
        "        return None\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\" Error: The content downloaded from '{url}' is not valid JSON.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred while loading data: {e}\")\n",
        "        return None\n",
        "\n",
        "#  LOADING CLINICAL DATA\n",
        "print(\"\\n Loading clinical data.\")\n",
        "\n",
        "# jsonfile da url perferisco cos√¨ e non da locale\n",
        "json_url = \"https://raw.githubusercontent.com/Profession-AI/progetti-deeplearning/refs/heads/main/Sintesi%20automatica%20di%20cartelle%20cliniche%20di%20un%E2%80%99azienda%20ospedaliera/hospital_records.json\"\n",
        "clinical_data = load_clinical_data(json_url)\n",
        "\n",
        "# piccolo if controlla se i dati sono stati caricati correttamente, in caso contrario, stampa un errore\n",
        "if clinical_data is None:\n",
        "    print(\" Failed to load data. Using example data.\")\n",
        "    clinical_data = []\n",
        "else:\n",
        "    print(f\" Loaded {len(clinical_data)} patients from the JSON file\")\n",
        "\n",
        "# PROCESSING AND GENERATING SUMMARIES\n",
        "if clinical_data is None or len(clinical_data) == 0:\n",
        "    print(\" No data available for processing. Exiting.\")\n",
        "    exit()\n",
        "\n",
        "print(\"\\n Generating clinical summaries.\")\n",
        "summaries = [] # elenco per memorizzare i riepiloghi generati per tutti i pazienti\n",
        "\n",
        "# cilco for per scorrere la cartella di ogni paziente per generare un riepilogo\n",
        "for i, patient in enumerate(clinical_data, 1):\n",
        "    print(f\"Processing {patient['patient_name']} ({i}/{len(clinical_data)})\")\n",
        "\n",
        "    # preparare il testo clinico concatenando le informazioni rilevanti\n",
        "    clinical_text = prepare_clinical_text(patient)\n",
        "\n",
        "    # genera il riepilogo utilizzando il modello BART\n",
        "    summary = generate_summary(clinical_text)\n",
        "    patient_summary = {\n",
        "        \"patient_name\": patient['patient_name'],\n",
        "        \"original_text_length\": len(clinical_text),\n",
        "        \"summary\": summary,\n",
        "        \"total_hospitalizations\": len(patient['hospitalizations'])\n",
        "    }\n",
        "\n",
        "    summaries.append(patient_summary)\n",
        "\n",
        "# SAVING RESULTS\n",
        "print(\"\\n Saving results.\")\n",
        "\n",
        "output_data = {\n",
        "    \"generation_date\": datetime.now().isoformat(),  #data e ora della generazione del file, in formato leggibile\n",
        "    \"model_used\": model_name,                       #nome del modello NLP utilizzato\n",
        "    \"total_patients\": len(clinical_data),           # numero totale di pazienti elaborati\n",
        "    \"summaries\": summaries                          #lista dei riassunti generati, uno per ciascun paziente\n",
        "}\n",
        "\n",
        "# poi adesso in questo piccolo blocco salvo i risult<ti in json\n",
        "try:\n",
        "    with open('clinical_summaries.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
        "    print(\" File 'clinical_summaries.json' saved successfully!\")\n",
        "except IOError as e:\n",
        "    print(f\" Error saving output file: {e}\")\n",
        "\n",
        "#DISPLAYING RESULTS\n",
        "print(\"\\nüìä GENERATED RESULTS:\")\n",
        "\n",
        "\n",
        "for summary_item in summaries:\n",
        "    print(f\"\\n{summary_item['patient_name']}\")\n",
        "    print(f\" Original text length: {summary_item['original_text_length']} characters\")\n",
        "    print(f\"Total hospitalizations: {summary_item['total_hospitalizations']}\")\n",
        "    print(f\" Summary: {summary_item['summary']}\")\n",
        "\n",
        "\n",
        "#FINAL STATISTICS\n",
        "print(\"\\nüìà FINAL STATISTICS:\")\n",
        "# calcola i ricoveri totali di tutti i pazienti elaborati\n",
        "total_hospitalizations = sum(s['total_hospitalizations'] for s in summaries)\n",
        "#calcola la lunghezza media del testo originale\n",
        "avg_text_length = sum(s['original_text_length'] for s in summaries) / len(summaries)\n",
        "\n",
        "print(f\"üë• Patients processed: {len(summaries)}\")\n",
        "print(f\"üè• Total hospitalizations: {total_hospitalizations}\")\n",
        "print(f\"üìè Average original text length: {avg_text_length:.0f} characters\")\n",
        "print(f\"ü§ñ Model used: {model_name}\")\n",
        "print(f\"üíª Device: {device}\")\n",
        "\n",
        "print(\"\\n Processing completed successfully!\")\n",
        "print(\"The system is now ready for use in a hospital environment!\")\n",
        "\n",
        "# Raffaele Diomaiuto studente del corso AI Development"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFfg-o0eMngQ",
        "outputId": "d5188af9-4e2c-42b9-9ead-1360c9d8970a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üè• Automatic clinical record synthesis system\n",
            "Loading BART model\n",
            "Model loaded on: cuda\n",
            "\n",
            " Loading clinical data.\n",
            " Loading data from URL: https://raw.githubusercontent.com/Profession-AI/progetti-deeplearning/refs/heads/main/Sintesi%20automatica%20di%20cartelle%20cliniche%20di%20un%E2%80%99azienda%20ospedaliera/hospital_records.json\n",
            " Loaded 10 patients from the JSON file\n",
            "\n",
            " Generating clinical summaries.\n",
            "Processing Patient 1 (1/10)\n",
            "Processing Patient 2 (2/10)\n",
            "Processing Patient 3 (3/10)\n",
            "Processing Patient 4 (4/10)\n",
            "Processing Patient 5 (5/10)\n",
            "Processing Patient 6 (6/10)\n",
            "Processing Patient 7 (7/10)\n",
            "Processing Patient 8 (8/10)\n",
            "Processing Patient 9 (9/10)\n",
            "Processing Patient 10 (10/10)\n",
            "\n",
            " Saving results.\n",
            " File 'clinical_summaries.json' saved successfully!\n",
            "\n",
            "üìä GENERATED RESULTS:\n",
            "\n",
            "Patient 1\n",
            " Original text length: 515 characters\n",
            "Total hospitalizations: 2\n",
            " Summary: Patient 1: Diagnosis: Pneumonia. Medications administered: Captopril, Prednisone, Ciprofloxacin, Ibuprofen. Patient 2: CT scan shows inflammation. MRI indicates tissue damage. Prognosis: Surgery recommended.\n",
            "\n",
            "Patient 2\n",
            " Original text length: 841 characters\n",
            "Total hospitalizations: 3\n",
            " Summary: Patient 1 has Arthritis, Diabetes and hypertension. Patient 2 has a fractured leg and a history of hypertension. Both patients are expected to make a full recovery, according to the hospital. The patient's condition is currently being monitored by the hospital's medical team.\n",
            "\n",
            "Patient 3\n",
            " Original text length: 280 characters\n",
            "Total hospitalizations: 1\n",
            " Summary: Patient: Patient 3 Hospitalization 1: From 2023-06-26. Diagnosis: Hypertension. Anamnesis: Frequent respiratory issues. Medications administered: Amoxicillin, Metformin, Paracetamol, Captopril. Prognosis: Complete recovery.\n",
            "\n",
            "Patient 4\n",
            " Original text length: 492 characters\n",
            "Total hospitalizations: 2\n",
            " Summary: Patient 4 was diagnosed with Pneumonia, Hypertension, and anamnesis. Patient 4 was admitted to the hospital with pneumonia and an amnnesis of hypertension. The patient is now recovering and is on the road to recovery.\n",
            "\n",
            "Patient 5\n",
            " Original text length: 820 characters\n",
            "Total hospitalizations: 3\n",
            " Summary: Patient 5 was diagnosed with heart failure and Bronchitis. Patient 5 was also diagnosed with a history of hypertension and a diabetic patient. The patient was admitted to the hospital with an anamnesis of heart failure. He was also admitted with bronchitis and a Diabetic patient and was being treated with antibiotics.\n",
            "\n",
            "Patient 6\n",
            " Original text length: 770 characters\n",
            "Total hospitalizations: 3\n",
            " Summary: Patient 6 was diagnosed with heart failure and kidney stones. He was also diagnosed with a history of hypertension and diabetes. Patient 6 was admitted to the hospital with a fractured skull. He is now recovering and is expected to make a full recovery.\n",
            "\n",
            "Patient 7\n",
            " Original text length: 524 characters\n",
            "Total hospitalizations: 2\n",
            " Summary: Patient: Patient 7 Hospitalization 1: From 2023-04-26 to2023-05-01. Diagnosis: Appendicitis. Anamnesis: Diabetic patient. Medications administered: Amoxicillin, Losartan, Metformin.\n",
            "\n",
            "Patient 8\n",
            " Original text length: 265 characters\n",
            "Total hospitalizations: 1\n",
            " Summary: Diabetic patient. CT scan shows inflammation. Medications administered: Metformin, Prednisone, Ibuprofen. Prognosis: Requires further monitoring. Patient 8. Hospitalization 1: From 2023-10-16 to 2023/10-30.\n",
            "\n",
            "Patient 9\n",
            " Original text length: 564 characters\n",
            "Total hospitalizations: 2\n",
            " Summary: Patient 9 has heart failure, arthritis, and respiratory issues. Patient 9 is expected to make a full recovery. The patient's condition is described as \"stable\" and \"stable-to-disease-like\" Patient 9 has been treated with Losartan, Ibuprofen, Prednisone and Omeprazole.\n",
            "\n",
            "Patient 10\n",
            " Original text length: 573 characters\n",
            "Total hospitalizations: 2\n",
            " Summary: Patient: Patient 10 Hospitalization 1: From 2023.08-30 to 2023-08-31. Diagnosis: Appendicitis. Anamnesis: No prior conditions. Medications administered: Prednisone, Ibuprofen.\n",
            "\n",
            "üìà FINAL STATISTICS:\n",
            "üë• Patients processed: 10\n",
            "üè• Total hospitalizations: 21\n",
            "üìè Average original text length: 564 characters\n",
            "ü§ñ Model used: facebook/bart-large-cnn\n",
            "üíª Device: cuda\n",
            "\n",
            " Processing completed successfully!\n",
            "The system is now ready for use in a hospital environment!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xW5iL14UOV77"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}